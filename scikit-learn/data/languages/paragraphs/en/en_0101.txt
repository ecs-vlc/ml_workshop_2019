Wikipedia receives between 25,000 and 60,000 page requests per second, depending on time of day.[260] As of 2008[update] page requests are first passed to a front-end layer of Squid caching servers.[261][needs update] Further statistics, based on a publicly available 3-month Wikipedia access trace, are available.[262] Requests that cannot be served from the Squid cache are sent to load-balancing servers running the Linux Virtual Server software, which in turn pass them to one of the Apache web servers for page rendering from the database. The web servers deliver pages as requested, performing page rendering for all the language editions of Wikipedia. To increase speed further, rendered pages are cached in a distributed memory cache until invalidated, allowing page rendering to be skipped entirely for most common page accesses.