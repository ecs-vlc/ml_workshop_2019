{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial has https://github.com/jonhare/DISCnetMachineLearningCourse/blob/master/Monday/ml101-tutorial/tutorial.md as a starting point.\n",
    "\n",
    "For the completion of this tutorial, you need to be comfortable with basic python. It is organised as follows:\n",
    "- loading and understanding the structure of the dataset \n",
    "- feature extraction: Bag of Words\n",
    "- introduction in sklearn to:\n",
    "    * unsupervised methods: K-Means\n",
    "    * supervised methods: KNN and SVM\n",
    "- parameter tuning: grid search\n",
    "- dealing with data: unbalanced datasets\n",
    "\n",
    "Although we present the core idea of the three algorithms, we strongly encourage you to have a closer look at the theoretical aspect, especially in the case of SVMs. \n",
    " \n",
    " We will work with the \"Twenty Newsgroups\" dataset, which consists of roughly 20K documents belonging to 20 (balanced) newsgroups.\n",
    "The dataset is available at https://github.com/ecs-vlc/ml_workshop_2019/raw/master/scikit-learn/data.zip.\n",
    "We can use the urllib module to download the \"data.zip\" file from the given URL, which we then decompress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://github.com/jonhare/DISCnetMachineLearningCourse/raw/master/Monday/ml101-tutorial/data.zip\", \"data.zip\")\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"data.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully running the code above, you should now see in your current working directory the \"data\" folder. Note that for this part we are only interested in one of the subdirectories: \"data/twenty_newsgroups\". You can navigate through it and familiarise yourself with the structure of the data set. The data is split into training and testing. Within each of the training and testing folders are 20 folders representing the 20 different newsgroups. Within these folders are the actual messages posted on the newsgroups, with one file per message. You are encouraged to spend some time to open a few of the files in a text editor to see their contents.  \n",
    "\n",
    "Before loading the data set, let us initially choose a subset of only 4 categories out of the 20 available for faster execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = load_files('data/twenty_newsgroups/train',categories=categories, shuffle=True, random_state=42, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dataset is a `scikit-learn` \"bunch\": a simple holder object with fields that can be both accessed as python `dict` keys or `object` attributes for convenience, for instance the `target_names` holds the list of the requested category names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files themselves are loaded in memory in the data attribute. Let us check that the number of training examples is 2257."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will look at both supervised (assigning each example to a known, given class. In our case, one of the four categories we selected) and unsupervised learning (classifying data points as belonging to a \"conceptual\" class which we identify in our data set. This concept will hopefully become clearer later on).\n",
    "\n",
    "Supervised learning algorithms will require a category label for each document in the training set, which is our target. For speed and space efficiency reasons scikit-learn loads the target attribute as an array of integers that corresponds to the index of the category name in the target_names list. The category integer ID of each sample is stored in the target attribute. As an example, we print the labels of the first 15 training examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 2 0 1 1 3 3 2 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that the samples have been shuffled randomly (with a fixed random number generator seed), as when loading the files we set the `shuffle` attribute to `True`. \n",
    "This is useful if you select only the first samples to quickly train a model and get a first idea of the results before re-training on the complete dataset. We will make use of this later on in our tutorial.\n",
    "\n",
    "For this data set, the category is the name of the newsgroup which also happens to be the name of the folder holding the individual documents. \n",
    "Check that this is the case for the first example in our training data. \n",
    "In the code block below, print the file name (use the `filenames` attribute) and the label of the first training example. As seen above, the target attribute stores an ID. To link that ID to a category name, use the `target_names` attribute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know which class the first example belongs to. Let us have a look at its first lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: clipper@mccarthy.csd.uwo.ca (Khun Yee Fung)\n",
      "Subject: Re: looking for circle algorithm faster than Bresenhams\n",
      "Organization: Department of Computer Science, The University of Western\n",
      "\tOntario, London, Ontario, Canada\n",
      "In-Reply-To: graeme@labtam.labtam.oz.au's message of Wed, 14 Apr 1993 04:49:46 GMT\n",
      "\t<1993Apr13.025240.8884@nwnexus.WA.COM>\n",
      "\t<1993Apr14.044946.12144@labtam.labtam.oz.au>\n",
      "Nntp-Posting-Host: mccarthy.csd.uwo.ca\n",
      "Lines: 41\n",
      "\n",
      ">>>>> On Wed, 14 Apr 1993 04:49:46 GMT, graeme@labtam.labtam.oz.au (Graeme Gill) said:\n",
      "\n",
      "Graeme> \tYes, that's known as \"Bresenhams Run Length Slice Algorithm for\n",
      "Graeme> Incremental lines\". See Fundamental Algorithms for Computer Graphics,\n",
      "Graeme> Springer-Verlag, Berlin Heidelberg 1985.\n",
      "\n",
      "> I have tried to extrapolate this to circles but I can't figure out\n",
      "> how to determine the length of the slices. Any ideas?\n",
      "\n",
      "Graeme> \tHmm. I don't think I can help you with this, but you might\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we familiarised ourselves with the dataset, let's extract some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction: Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To feed text to our machine learning algorithm, we need to turn the text content into numerical, fixed-length feature vectors. The most intuitive way to do so is the _Bags of Words_ (BoW) representation. A bag is simply a set that allows repetitions.\n",
    "\n",
    "When building a BoW the first step is to break the text into its constituent words, which we refer to as _tokenisation_ and then count the number of times each word in our corpus appears in a document. With `scikit-learn` we can easily transform texts to feature vectors and then get the desired count using a `CountVectorizer`.\n",
    "\n",
    "The `CountVectorizer` produces a sparse representation, as the bag of words implies that `n_features` is the number of distinct words in the corpus: this number is typically larger that 100,000. But most counts will be zero, as a given text usually contains a limited vocabulary. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `X_train_counts` holds a term-document matrix which counts the number of times each of the 35788 features is present in each of the 2257 texts. CountVectorizer also supports counts of N-grams of words or consecutive characters. N-grams are runs of consecutive characters or words, so for example in the case of word bi-grams, every consecutive pair of words would be a feature. \n",
    "\n",
    "Once fitted, the vectorizer has built a dictionary of feature indices in which you can search a term to get its ID. Use the code block below to find the number of times the term 'algorithm' is present in the first document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a fixed integer ID for each word occurring in any document of the training set and for each document, we have a count of occurrences of each word. One problem with the simple count of occurrences is that it does not account for the document length. Instead, we can calculate the _term frequency_ (tf), which is simply the ratio of the number of times a word occurs in a text and the total number of terms in that text.\n",
    "\n",
    "Another important aspect we want to account for is that words are not equally informative. We want to prioritise words that are less frequent across different texts, as they are more likely to indicate the topic. We can do this by weighting the terms according to their _inverse document frequency_ (idf): the number of documents divided by the number of documents a word appears in.\n",
    "\n",
    "`Scikit-learn` allows us to combine these two refinements into what is referred to as \"Term Frequency-Inverse Document Frequency\" (tf–idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "print(X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print out the scores corresponding the words in the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 98)\t0.03566881875032108\n",
      "  (0, 124)\t0.07133763750064216\n",
      "  (0, 137)\t0.03566881875032108\n",
      "  (0, 336)\t0.03566881875032108\n",
      "  (0, 448)\t0.03566881875032108\n",
      "  (0, 587)\t0.07133763750064216\n",
      "  (0, 1093)\t0.03566881875032108\n",
      "  (0, 1095)\t0.03566881875032108\n",
      "  (0, 1097)\t0.03566881875032108\n",
      "  (0, 1101)\t0.03566881875032108\n",
      "  (0, 1102)\t0.07133763750064216\n",
      "  (0, 1118)\t0.03566881875032108\n",
      "  (0, 1119)\t0.03566881875032108\n",
      "  (0, 1690)\t0.03566881875032108\n",
      "  (0, 1723)\t0.03566881875032108\n",
      "  (0, 1989)\t0.03566881875032108\n",
      "  (0, 1996)\t0.03566881875032108\n",
      "  (0, 2044)\t0.03566881875032108\n",
      "  (0, 2079)\t0.03566881875032108\n",
      "  (0, 2203)\t0.03566881875032108\n",
      "  (0, 2303)\t0.07133763750064216\n",
      "  (0, 2350)\t0.07133763750064216\n",
      "  (0, 2427)\t0.07133763750064216\n",
      "  (0, 2513)\t0.03566881875032108\n",
      "  (0, 2562)\t0.03566881875032108\n",
      "  :\t:\n",
      "  (0, 32131)\t0.03566881875032108\n",
      "  (0, 32139)\t0.03566881875032108\n",
      "  (0, 32142)\t0.14267527500128432\n",
      "  (0, 32253)\t0.03566881875032108\n",
      "  (0, 32270)\t0.07133763750064216\n",
      "  (0, 32439)\t0.03566881875032108\n",
      "  (0, 32467)\t0.03566881875032108\n",
      "  (0, 32493)\t0.17834409375160543\n",
      "  (0, 32898)\t0.03566881875032108\n",
      "  (0, 33597)\t0.07133763750064216\n",
      "  (0, 33968)\t0.10700645625096325\n",
      "  (0, 34199)\t0.03566881875032108\n",
      "  (0, 34470)\t0.03566881875032108\n",
      "  (0, 34481)\t0.03566881875032108\n",
      "  (0, 34571)\t0.03566881875032108\n",
      "  (0, 34660)\t0.03566881875032108\n",
      "  (0, 34809)\t0.07133763750064216\n",
      "  (0, 34896)\t0.07133763750064216\n",
      "  (0, 35157)\t0.03566881875032108\n",
      "  (0, 35168)\t0.03566881875032108\n",
      "  (0, 35382)\t0.07133763750064216\n",
      "  (0, 35584)\t0.03566881875032108\n",
      "  (0, 35592)\t0.14267527500128432\n",
      "  (0, 35601)\t0.03566881875032108\n",
      "  (0, 35638)\t0.10700645625096325\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, find the words corresponding to the first two non-zero entries; that is, words with IDs 2044 and 14085. Reflect on why they might have small weights relating back to both term frequency and inverse document frequency. Also, identify the word with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than transforming the raw counts with the `TfidfTransformer`, it is alternatively possible to use the `TfidfVectorizer` to directly parse the dataset. The advantage of doing this is that it can automatically filter out less informative words on the basis of stop-words, document frequency, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 18188)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english',max_df=0.5,min_df=2)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(twenty_train.data)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output, the number of features was reduced from 35788 to 18188 using this approach. We will use these features for all of the algorithms that we will look at today, starting with K-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means clustering\n",
    "\n",
    "To better understand unsupervised learning and also to get a better understanding of our dataset, for this section we will pretend we don't know what the possible classes are. That is, we will ignore the labels and experiment with clustering, which essentially means grouping data points based on a similarity measure. We'll use K-Means as its one of the most intuitive clustering methods, although it does have a few limitations This blog (https://www.inovex.de/blog/disadvantages-of-k-means-clustering/) discusses it in the context of anomaly detection but does a good job of highlighting some of the issues. \n",
    "\n",
    "If you are unfamiliar with the K-means algorithm, the Wikipedia page (https://en.wikipedia.org/wiki/K-means_clustering) provides a clear description and an illustration of how it works. The idea is to find K clusters in the data in an unsupervised manner. Each cluster has a _centroid_ (mean).\n",
    "Means are initialised randomly and then, until convergence, data points are assigned to the closest group and centroids are updated.\n",
    "\n",
    "We initially perform K-means with `k_clusters = 4` clusters as we restricted our data to 4 categories, but we will get to experiment with different values. An important aspect to remember is that K-means has a random initialisation element to the algorithm. You can choose to set the `random_state` if you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=4, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_clusters = 4\n",
    "km = KMeans(k_clusters)\n",
    "km.fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignments of the original posts to cluster ID is given by `km.labels_` once `km.fit(..)` has been called. The array of cluster centroids is given by `km.cluster_centers_`. Intuitively, the vector that describes the centre of a cluster is just like any other featurevector. Every element can be interpreted as the number of times a specific term occurs (or the tf-idf weight of a specific term) in a hypothetical document. An interesting way to explore what each cluster is representing is to calculate and print the top weighted (either by the occurrence or tf-idf) terms for that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: god jesus people believe bible christians faith christian hell christ\n",
      "Cluster 1: pitt geb banks gordon cs cadre dsl shameful n3jxp surrender\n",
      "Cluster 2: com university article posting graphics host nntp know like msg\n",
      "Cluster 3: keith caltech livesey sgi wpd solntze schneider jon cco morality\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vect.get_feature_names()\n",
    "for i in range(k_clusters):\n",
    "    print(\"Cluster %d:\" % i, end=\"\")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of different metrics exist that allow us to measure how well the clusters fit the known distribution of underlying newsgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.258\n",
      "Completeness: 0.421\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(twenty_train.target, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(twenty_train.target, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneity and completeness are measures between 0 and 1. A homogeneity of 1 indicates that the clusters match the original labels exactly. Completeness of 1 means that all members of one class are assigned to the same centroid. Experiment with how different values of `k_clusters` influence the two.\n",
    "\n",
    "Finally, print out the targets (which you don't normally have in an unsupervised setting) and the identified labels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now identify the cluster to which the 10th training example was attributed to using `km.labels_`, the target and the name of that target. `KMeans` simply outputs a label, which is an integer. As a supervised method, it does not immediately identify the label with one of the four categories. On the other hand, for the target, as we have seen above, we can go from an integer to a class name in a straightforward manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a predictive model using K-nearest Neighbours (KNN)\n",
    "\n",
    "Moving to supervised methods, we train a classifier to try to predict the category of a post. Let's start with a KNN classifier, which provides a simple baseline, although is perhaps not the best classifier for this task. Essentially, KNN associates each instance to the same class as the majority of its k neighbours in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3).fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call transform instead of fit_transform on the transformers/vectorizers since they have already been fitted to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God does not exist' => alt.atheism\n",
      "'God exists' => soc.religion.christian\n",
      "'The procedure is non-invasive' => sci.med\n",
      "'These are 24 bit color images.' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God does not exist', 'God exists' , 'The procedure is non-invasive' , 'These are 24 bit color images.']\n",
    "X_new_tfidf = tfidf_vect.transform(docs_new)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the vectorizer => [transformer] => classifier easier to work with, `scikit-learn` provides a `Pipeline` class that behaves like a compound classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf_KNN = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf_KNN = text_clf_KNN.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate the accuracy given by the average number of correct predictions divided by the number of total predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723035952063915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = load_files('data/twenty_newsgroups/test', categories=categories, shuffle=True, random_state=42, encoding='latin1')\n",
    "predicted = text_clf_KNN.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we achieved a 77.2% accuracy. Let's see if we can do better with a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (when used with suitable features). \n",
    "The main idea of SVMs is to find a separating hyperplane that gives the largest margin between the classes. Have a look at this article to get an intuition on margins: https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47.\n",
    "\n",
    "We can change the learner by just plugging a different classifier object into our pipeline. Note that we also save the accuracy, as we will need it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9081225033288948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_SVM = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, max_iter=5, tol=None,\n",
    "                                           random_state=42)),\n",
    "])\n",
    "_ = text_clf_SVM.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_SVM = text_clf_SVM.predict(twenty_test.data)\n",
    "acc_SVM = np.mean(predicted_SVM == twenty_test.target)\n",
    "print(acc_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.59      0.88      0.70       319\n",
      "         comp.graphics       0.92      0.80      0.86       389\n",
      "               sci.med       0.89      0.61      0.73       396\n",
      "soc.religion.christian       0.79      0.82      0.80       398\n",
      "\n",
      "           avg / total       0.81      0.77      0.78      1502\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAD8CAYAAADqmhgGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNRLwIqI1EvAiojUS8CKiNRLwIqI1/j+HZTIK6sUXkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b0bed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
    "im = plt.imshow(metrics.confusion_matrix(twenty_test.target, predicted), interpolation='nearest')\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that posts from the newsgroups on atheism and christianity are more often confused for one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning using grid search\n",
    "\n",
    "We've already encountered some parameters such as `use_idf` in the `TfidfTransformer` (and `TfidfVectorizer`). Classifiers tend to have many parameters as well; e.g., `KNeighborsClassifier` includes parameter for the number of neighbours and `SGDClassifier` has a penalty parameter `alpha` and configurable loss and penalty terms in the objective function (see the module documentation, or use the Python help function, to get a description of these).\n",
    "\n",
    "Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. Let's use this to explore whether we can make the `KNeighborsClassifier` perform as well as our linear SVM. We'll try out classifiers on either words or bi-grams, with or without idf, and with a K (number of neighbours) ranging from 1 to 7 (odd numbers only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__n_neighbors': (1, 3, 5, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eight parameter combinations in parallel with the `n_jobs` parameter. If we give this parameter a value of -1, grid search will detect how many cores are available and use them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf_KNN, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search instance behaves like a normal scikit-learn model. Let's perform the search on a smaller subset of the training data to speed up the computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 400\n",
    "gs_clf = gs_clf.fit(twenty_train.data[:train_size], twenty_train.target[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of calling `fit` on a `GridSearchCV` object is a classifier that we can use to `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `predict` returns an array of predictions, as we usually want to get predictions for multiple examples at a time, so to get the target name, we need to get the first of our predictions. The object’s `best_score_` and `best_params_` attributes store the best mean score and the parameters setting corresponding to that score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__n_neighbors: 5\n",
      "tfidf__ngram_range: (1, 2)\n",
      "tfidf__use_idf: True\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using `GridSearchCV` together with the `SGDClassifier` SVM classifier we defined above to find the optimal `alpha`, together with the optimal `ngram` range and use idf parameters for the vectoriser. How does the classification accuracy compare to the K-Nearest-Neighbours classifier? How does the performance change if we increase the `train_size`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you build a classifier for the entire 20 class dataset? What is the performance, and how does it compare to the 4 classes we have been experimenting with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced datasets\n",
    "\n",
    "From the point of view of data distribution, the dataset we've been working with is very convenient. We extend the original dataset with a new class, which we call `alt.atheism.reduced`, to explore the difficulties that can arise with unbalanced datasets. This new class only contains a small fraction of the original `alt.atheism` category.\n",
    "\n",
    "We start by reminding ourselves what accuracy we obtained using the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9081225033288948\n"
     ]
    }
   ],
   "source": [
    "print(acc_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load again the data belonging to the same four categories, except `alt.atheism`, which we replace with the new class and then use the same pipeline as before to obtain our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9332220367278798\n"
     ]
    }
   ],
   "source": [
    "categories_un = ['alt.atheism.reduced', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train_un = load_files('data/twenty_newsgroups/train',categories=categories_un, shuffle=True, random_state=42, encoding='latin1')\n",
    "_ = text_clf_SVM.fit(twenty_train_un.data, twenty_train_un.target)\n",
    "twenty_test_un = load_files('data/twenty_newsgroups/test', categories=categories_un, shuffle=True, random_state=42, encoding='latin1')\n",
    "predicted_un = text_clf_SVM.predict(twenty_test_un.data)\n",
    "print(np.mean(predicted_un == twenty_test_un.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a slight improvement in accuracy. Let's take a closer look at our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "   alt.atheism.reduced       1.00      0.27      0.42        15\n",
      "         comp.graphics       0.89      0.98      0.93       389\n",
      "               sci.med       0.98      0.89      0.93       396\n",
      "soc.religion.christian       0.94      0.96      0.95       398\n",
      "\n",
      "           avg / total       0.94      0.93      0.93      1198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test_un.target, predicted_un, target_names=twenty_test_un.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh3BANzPrEA7oZmYd4v8D+DmS+gILcJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19315a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"atheism.red\", \"christian\", \"graphics\", \"med\"]\n",
    "cm = metrics.confusion_matrix(twenty_test_un.target, predicted_un)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm, vmin = 0, vmax = 1700)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted category')\n",
    "plt.ylabel('True category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened here? As we have seen, with the original dataset the separation between `alt.atheism` and `soc.religion.christian` was not very clear and having an overwhelming number of examples from one of the classes made the two groups even less distinguishable. Yet, the accuracy has increased. For this reason, we must be very careful when choosing a metric, as it can be misleading. In the case of unbalanced datasets, the AUROC (Area under reciever operator characteristic) and AUPR (Area under precision recall) curves are more indicative of how well we perform on unseen data.\n",
    "\n",
    "Think about having to diagnose whether patients have a rare disease or not. Naturally, we would have more data about healthy patients. If we do not choose our measure of performance carefully, our machine might end up labelling all patients as healthy, as it is more probable that a person does not suffer of a rare disease. In the case of newsgroup classification, the fact that the classifier cannot distinguish the two categories doesn't seem that much of a problem. However a medical classifier not being able to identify ill patients would be more problematic.\n",
    " \n",
    "This article (https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28) extensively explains the problem both intuitively and from a statistical point of view and point out some limitations of the popular work-around methods. The same article discusses confusion matrices, precision, recall and F1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis prediction\n",
    "\n",
    "Now it's your turn to build a classification pipeline to predict whether a review is negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = load_files('data/movie_reviews/txt_sentoken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the data does not come with training and testing data so we will need to do the split ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our reviews are stored in `doc_train` and `doc_test`, while the targets are in `y_train` and `y_test`. Build a classification pipeline that filters uninformative terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search to decide between using unigrams or bigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test data and print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
