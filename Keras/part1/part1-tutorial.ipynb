{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "output.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "pycharm-48995b13",
      "language": "python",
      "display_name": "PyCharm (vae-channels)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLlqGa4SKd2N",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "# Learning to Deep Learn using Python, Keras, TensorFlow and a GPU\n",
        "\n",
        "_[Jonathon Hare, 21st Jan 2018](https://github.com/jonhare/DISCnetMachineLearningCourse)_\n",
        "\n",
        "## Change History\n",
        "\n",
        "- 20170308: Initial version\n",
        "- 20170403: Update to use Keras 2 API\n",
        "- 20180121: Update for LR\n",
        "- 20180416: Update for DISCnet\n",
        "- 20190408: Update for DISCnet/2 + Colab\n",
        "\n",
        "## Acknowledgements\n",
        "This part of the course is largely based on Jason Brownlee\u0027s [\"Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras\"](http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/) tutorial. A number of changes have been made to ensure that it better fits our format, and I\u0027ve added additional bits and exercises throughout. This version extends on one that Jon Hare ran for the VLC research group in October 2016 and a revised version for Ordnance Survey in April 2017.\n",
        "\n",
        "## Introduction \n",
        "A popular demonstration of the capability of deep learning techniques is object recognition in image data. The \"hello world\" of object recognition for machine learning and deep learning is the MNIST dataset for handwritten digit recognition.\n",
        "\n",
        "In this part of the tutorial you will discover how to develop a deep learning model to achieve near state of the art performance on the MNIST handwritten digit recognition task in Python using the Keras deep learning library.\n",
        "\n",
        "Through this part of the tutorial you\u0027ll learn how to:\n",
        "\n",
        "* How to load the MNIST dataset in Keras.\n",
        "* How to develop and evaluate a baseline neural network model for the MNIST problem.\n",
        "* How to switch the backends used by Keras and run your code on the GPU.\n",
        "* How to implement and evaluate a simple Convolutional Neural Network for MNIST.\n",
        "* How to implement a close to state-of-the-art deep learning model for MNIST.\n",
        "* How to serialise and deserialise trained models.\n",
        "* How to load your own image created outside of the MNIST dataset, and pass it through the network.\n",
        "* How to visualise the filters learned by the network.\n",
        "* How to implement networks with branching and merging.\n",
        "\n",
        "## Prerequisites\n",
        "To use this tutorial you\u0027ll use the Python 3 language with the `keras` deep learning library and the `tensorflow` backend. We\u0027ll also use the `scikit-learn` and `numpy` packages. For this lab we\u0027ll use a Jupyter notebook running in the cloud on [Google Colab](https://colab.research.google.com). Colab gives us free access to a virtual machine with GPU acceleration and all the prerequisite libraries pre-installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPGBusNuKd2P",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "__Note:__ in Jupyter Notebooks, commands with an exclaimation mark (!) in front of them are shell commands, and will run just as if typed in a terminal (without the exclaimation mark)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ma2m-lKd2U",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "If running locally you\u0027ll need access to a computer with the following installed:\n",
        "\n",
        "- `Python` (\u003e 3.6)\n",
        "- `keras` (\u003e\u003d 2.0.0)\n",
        "- `tensorflow` (\u003e\u003d 1.0.0)\n",
        "- `NumPy` (\u003e\u003d 1.12.1)\n",
        "- `SciPy` (\u003e\u003d 0.19.1)\n",
        "- `scikit-learn` (\u003e\u003d 0.19.1)\n",
        "\n",
        "If you\u0027ve installed the base Anaconda python distribution, then running `conda install keras` will install both keras and tensorflow. You can make a start on this tutorial using you own machines, however you\u0027ll find that the code runs rather slowly. To run at more sensible speeds you need access to a machine with a powerful GPU (or GPUs).\n",
        "\n",
        "## The MNIST Dataset\n",
        "MNIST is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem.\n",
        "\n",
        "The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset.\n",
        "\n",
        "Images of digits were taken from a variety of scanned documents, normalized in size and centred. This makes it an excellent dataset for evaluating models, allowing the developer to focus on the machine learning with very little data cleaning or preparation required.\n",
        "\n",
        "Each image is a 28 by 28 pixel square (784 pixels total). A standard spit of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\n",
        "\n",
        "It is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. Results are reported using prediction error, which is nothing more than the inverted classification accuracy.\n",
        "\n",
        "Excellent results achieve a prediction error of less than 1%. State-of-the-art prediction error of approximately 0.2% can be achieved with large Convolutional Neural Networks. There is a listing of the state-of-the-art results and links to the relevant papers on the MNIST and other datasets on [Rodrigo Benenson’s webpage](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354).\n",
        "\n",
        "## Loading the MNIST dataset in Keras\n",
        "\n",
        "The Keras deep learning library provides a convenience method for loading the MNIST dataset.\n",
        "\n",
        "The dataset is downloaded automatically the first time this function is called and is stored in your home directory in `~/.keras/datasets/mnist.pkl.gz` as a 15MB file.\n",
        "\n",
        "This is very handy for developing and testing deep learning models.\n",
        "\n",
        "To demonstrate how easy it is to load the MNIST dataset, we will first write a little script to download and visualize the first 4 images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PklBebvKd2V",
        "colab_type": "code",
        "outputId": "242e3a2c-2b38-4452-919d-f817555f8127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "pycharm": {}
      },
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) \u003d mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cFigure size 432x288 with 4 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH1Py81VKd2Y",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "You can see that downloading and loading the MNIST dataset is as easy as calling the `mnist.load_data()` function. Running the above example, you should see the image below.\n",
        "\n",
        "![Examples from the MNIST dataset](https://raw.githubusercontent.com/jonhare/vlc-deep-learning-labs/master/mnist-samples.png \"Examples from the MNIST dataset\")\n",
        "\n",
        "## Baseline Multi-Layer Perceptron Model\n",
        "\n",
        "Keras is a general purpose neural network toolbox. Before we start to look at deep convolutional architectures, we can start with something much simpler - a basic multilayer perceptron. Because the MNIST images are relatively small, a fully connected MLP network will have relatively few weights to train; with bigger images, an MLP might not be practical due to the number of weights.\n",
        "\n",
        "In this section we will create a simple multi-layer perceptron model with a single hidden layer that achieves an error rate of 1.74%. We will use this as a baseline for comparing more complex convolutional neural network models later.\n",
        "\n",
        "Let\u0027s start off by importing the classes and functions we will need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXPQSLlRKd2Z",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HobwnEawKd2c",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "When developing, it is always a good idea to initialize the random number generator to a constant to ensure that the results of your script are reproducible each time you run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BA8jq3NKd2d",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed \u003d 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSWv-nSUKd2g",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Now we can load the MNIST dataset using the Keras helper function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6zRfs1Kd2h",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) \u003d mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ4FkNKCKd2k",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "The training dataset is structured as a 3-dimensional array of instance, image width and image height. For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\n",
        "\n",
        "We can do this transform easily using the `reshape()` function on the NumPy array. We can also reduce our memory requirements by forcing the precision of the pixel values to be 32 bit, the default precision used by Keras anyway."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55_BO829Kd2l",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels \u003d X_train.shape[1] * X_train.shape[2]\n",
        "X_train \u003d X_train.reshape(X_train.shape[0], num_pixels).astype(\u0027float32\u0027)\n",
        "X_test \u003d X_test.reshape(X_test.shape[0], num_pixels).astype(\u0027float32\u0027)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hmi2MC_Kd2o",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "The pixel values are gray scale between 0 and 255. It is almost always a good idea to perform some scaling of input values when using neural network models. Because the scale is well known and well behaved, we can very quickly normalize the pixel values to the range 0 and 1 by dividing each value by the maximum of 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t130MsvlKd2p",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train \u003d X_train / 255\n",
        "X_test \u003d X_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb7RH8DbKd2t",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, it is good practice to use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix.\n",
        "\n",
        "We can easily do this using the built-in `np_utils.to_categorical()` helper function in Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WF2Vt9jKd2t",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# one hot encode outputs\n",
        "y_train \u003d np_utils.to_categorical(y_train)\n",
        "y_test \u003d np_utils.to_categorical(y_test)\n",
        "num_classes \u003d y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QiSHYLTKd2w",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "We are now ready to create our simple neural network model. We will define our model in a function. This is handy if you want to extend the example later and try and get a better score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg1KoBteKd2x",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel \u003d Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim\u003dnum_pixels, kernel_initializer\u003d\u0027normal\u0027, activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer\u003d\u0027normal\u0027, activation\u003d\u0027softmax\u0027))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d_Hl7HdKd2z",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "The model is a simple neural network with one hidden layer with the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer.\n",
        "\n",
        "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model\u0027s output prediction. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n",
        "\n",
        "We can now fit and evaluate the model. The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
        "\n",
        "Finally, the test dataset is used to evaluate the model and a classification error rate is printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itf96nT-Kd20",
        "colab_type": "code",
        "outputId": "8e9f6033-811d-4ece-ac8c-f2ad57898472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "pycharm": {}
      },
      "source": [
        "# build the model\n",
        "model \u003d baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data\u003d(X_test, y_test), epochs\u003d10, batch_size\u003d200, verbose\u003d2)\n",
        "# Final evaluation of the model\n",
        "scores \u003d model.evaluate(X_test, y_test, verbose\u003d0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.2783 - acc: 0.9210 - val_loss: 0.1412 - val_acc: 0.9575\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.1116 - acc: 0.9676 - val_loss: 0.0925 - val_acc: 0.9701\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0718 - acc: 0.9799 - val_loss: 0.0784 - val_acc: 0.9770\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0505 - acc: 0.9857 - val_loss: 0.0741 - val_acc: 0.9768\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0375 - acc: 0.9892 - val_loss: 0.0671 - val_acc: 0.9792\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0271 - acc: 0.9928 - val_loss: 0.0635 - val_acc: 0.9804\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0211 - acc: 0.9944 - val_loss: 0.0617 - val_acc: 0.9815\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0139 - acc: 0.9968 - val_loss: 0.0624 - val_acc: 0.9802\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0595 - val_acc: 0.9807\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0080 - acc: 0.9984 - val_loss: 0.0583 - val_acc: 0.9813\n",
            "Baseline Error: 1.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvKsMPdaKd22",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Running the example might take a few minutes when run on a CPU (probably around 9s per epoch, but might be slower if you\u0027re sharing the machine with others). However, by default when using the Tensorflow backend the GPU will be used if it\u0027s available, and each epoch will be a lot faster:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xJMHaoQKd23",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "Using TensorFlow backend.\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "Epoch 1/10\n",
        "2018-01-21 14:47:42.029792: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:47:42.029818: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:47:42.618171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
        "2018-01-21 14:47:42.618900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
        "name: GeForce GTX TITAN X\n",
        "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
        "pciBusID 0000:02:00.0\n",
        "Total memory: 11.92GiB\n",
        "Free memory: 11.80GiB\n",
        "2018-01-21 14:47:42.618923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
        "2018-01-21 14:47:42.618934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
        "2018-01-21 14:47:42.618949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -\u003e (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)\n",
        "5s - loss: 0.2775 - acc: 0.9213 - val_loss: 0.1390 - val_acc: 0.9581\n",
        "Epoch 2/10\n",
        "1s - loss: 0.1097 - acc: 0.9685 - val_loss: 0.0911 - val_acc: 0.9729\n",
        "Epoch 3/10\n",
        "1s - loss: 0.0703 - acc: 0.9804 - val_loss: 0.0822 - val_acc: 0.9753\n",
        "Epoch 4/10\n",
        "1s - loss: 0.0495 - acc: 0.9859 - val_loss: 0.0750 - val_acc: 0.9778\n",
        "Epoch 5/10\n",
        "1s - loss: 0.0364 - acc: 0.9896 - val_loss: 0.0658 - val_acc: 0.9800\n",
        "Epoch 6/10\n",
        "1s - loss: 0.0265 - acc: 0.9932 - val_loss: 0.0643 - val_acc: 0.9803\n",
        "Epoch 7/10\n",
        "1s - loss: 0.0200 - acc: 0.9950 - val_loss: 0.0622 - val_acc: 0.9809\n",
        "Epoch 8/10\n",
        "1s - loss: 0.0139 - acc: 0.9970 - val_loss: 0.0626 - val_acc: 0.9810\n",
        "Epoch 9/10\n",
        "1s - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0579 - val_acc: 0.9816\n",
        "Epoch 10/10\n",
        "1s - loss: 0.0081 - acc: 0.9984 - val_loss: 0.0566 - val_acc: 0.9821\n",
        "Baseline Error: 1.79%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7VX4tRWKd25",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "## Simple Convolutional Neural Network for MNIST\n",
        "\n",
        "Now that we have seen how to load the MNIST dataset and train a simple multi-layer perceptron model on it, we can now start to develop a more sophisticated convolutional neural network or CNN model.\n",
        "\n",
        "Keras provides a lot of capability for creating CNNs, and includes a large number of layer types and activation functions.\n",
        "\n",
        "In this section we will create a simple CNN for MNIST that demonstrates how to use all of the aspects of a modern CNN implementation, including Convolutional layers, Pooling layers and Dropout layers.\n",
        "\n",
        "The first step is to import the classes and functions needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH1TLqGcKd26",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G36CetvDKd28",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Again, we always initialize the random number generator to a constant seed value for reproducibility of results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q214gW9jKd29",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed \u003d 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO4qXbc8Kd2_",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Next we need to load the MNIST dataset and reshape it so that it is suitable for use training a CNN. In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [width][height][pixels].\n",
        "\n",
        "In the case of RGB, the third dimension, pixels, would be 3 for the red, green and blue components and it would be like having 3 image inputs for every colour image. In the case of MNIST where the pixel values are greyscale, the pixel dimension is set to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGw1x72OKd3A",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) \u003d mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train \u003d X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\u0027float32\u0027)\n",
        "X_test \u003d X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\u0027float32\u0027)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1d2Ex1HKd3C",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "As before, it is a good idea to normalize the pixel values to the range 0 and 1 and one-hot encode the output variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nsw0I57Kd3D",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train \u003d X_train / 255\n",
        "X_test \u003d X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train \u003d np_utils.to_categorical(y_train)\n",
        "y_test \u003d np_utils.to_categorical(y_test)\n",
        "num_classes \u003d y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0L7SiZIKd3I",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Next we define our neural network model.\n",
        "\n",
        "Convolutional neural networks are more complex than standard multi-layer perceptrons, so we will start by using a simple structure to begin with that uses all of the elements for state of the art results. Below summarizes the network architecture.\n",
        "\n",
        "1 The first hidden layer is a convolutional layer called a `Convolution2D`. The layer has 32 feature maps, which with the size of 5×5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above [width][height][pixels].\n",
        "2 Next we define a pooling layer that takes the max called `MaxPooling2D`. It is configured with a pool size of 2×2.\n",
        "3 The next layer is a regularization layer using dropout called `Dropout`. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
        "4 Next is a layer that converts the 2D matrix data to a vector called `Flatten`. It allows the output to be processed by standard fully connected layers.\n",
        "5 Next a fully connected layer with 128 neurons and rectifier activation function.\n",
        "6 Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n",
        "\n",
        "As before, the model is trained using logarithmic loss and the ADAM gradient descent algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hMVei6bKd3I",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel \u003d Sequential()\n",
        "\tmodel.add(Convolution2D(32, (5, 5), padding\u003d\u0027valid\u0027, input_shape\u003d(28, 28, 1), activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(Dense(num_classes, activation\u003d\u0027softmax\u0027))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCWihzpKd3M",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "We evaluate the model the same way as before with the multi-layer perceptron. The CNN is fit over 10 epochs with a batch size of 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "680aTPAeKd3N",
        "colab_type": "code",
        "outputId": "ec215ffc-2227-4f0e-ac2e-c86409500a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "pycharm": {}
      },
      "source": [
        "# build the model\n",
        "model \u003d baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data\u003d(X_test, y_test), epochs\u003d10, batch_size\u003d200, verbose\u003d2)\n",
        "# Final evaluation of the model\n",
        "scores \u003d model.evaluate(X_test, y_test, verbose\u003d0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate \u003d 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.2238 - acc: 0.9363 - val_loss: 0.0751 - val_acc: 0.9766\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.0711 - acc: 0.9785 - val_loss: 0.0465 - val_acc: 0.9841\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0506 - acc: 0.9847 - val_loss: 0.0420 - val_acc: 0.9860\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0404 - acc: 0.9874 - val_loss: 0.0386 - val_acc: 0.9868\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0320 - acc: 0.9902 - val_loss: 0.0342 - val_acc: 0.9885\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0334 - val_acc: 0.9903\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0339 - val_acc: 0.9898\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0342 - val_acc: 0.9885\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0304 - val_acc: 0.9896\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0316 - val_acc: 0.9905\n",
            "Baseline Error: 0.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRRNhHq6Kd3P",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Running the example, the accuracy on the training and validation test is printed each epoch and at the end of the classification error rate is printed.\n",
        "\n",
        "Epochs may take a second or so on the GPU, although will take a fair bit longer on the CPU (perhaps ~46s per epoch). You can see that the network achieves an error rate of 1.06, which is better than the simple multi-layer perceptron model above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1-rdnfeKd3Q",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "Using TensorFlow backend.\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "Epoch 1/10\n",
        "2018-01-21 14:49:59.159123: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:49:59.159149: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:49:59.412522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
        "2018-01-21 14:49:59.413240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
        "name: GeForce GTX TITAN X\n",
        "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
        "pciBusID 0000:02:00.0\n",
        "Total memory: 11.92GiB\n",
        "Free memory: 11.80GiB\n",
        "2018-01-21 14:49:59.413263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
        "2018-01-21 14:49:59.413272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
        "2018-01-21 14:49:59.413281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -\u003e (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)\n",
        "4s - loss: 0.2258 - acc: 0.9347 - val_loss: 0.0788 - val_acc: 0.9755\n",
        "Epoch 2/10\n",
        "2s - loss: 0.0703 - acc: 0.9793 - val_loss: 0.0478 - val_acc: 0.9847\n",
        "Epoch 3/10\n",
        "2s - loss: 0.0506 - acc: 0.9843 - val_loss: 0.0426 - val_acc: 0.9865\n",
        "Epoch 4/10\n",
        "2s - loss: 0.0397 - acc: 0.9875 - val_loss: 0.0399 - val_acc: 0.9867\n",
        "Epoch 5/10\n",
        "2s - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0346 - val_acc: 0.9876\n",
        "Epoch 6/10\n",
        "2s - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0322 - val_acc: 0.9897\n",
        "Epoch 7/10\n",
        "2s - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0357 - val_acc: 0.9884\n",
        "Epoch 8/10\n",
        "2s - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0309 - val_acc: 0.9886\n",
        "Epoch 9/10\n",
        "2s - loss: 0.0168 - acc: 0.9946 - val_loss: 0.0302 - val_acc: 0.9896\n",
        "Epoch 10/10\n",
        "2s - loss: 0.0138 - acc: 0.9952 - val_loss: 0.0305 - val_acc: 0.9894\n",
        "Baseline Error: 1.06%\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_7809Kd3T",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "## Larger Convolutional Neural Network for MNIST\n",
        "\n",
        "Now that we have seen how to create a simple CNN, let’s take a look at a model capable of close to state of the art results.\n",
        "\n",
        "We import classes and function then load and prepare the data the same as in the previous CNN example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4LSDGrDKd3U",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        " \n",
        "# fix random seed for reproducibility\n",
        "seed \u003d 7\n",
        "numpy.random.seed(seed)\n",
        " \n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) \u003d mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train \u003d X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\u0027float32\u0027)\n",
        "X_test \u003d X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\u0027float32\u0027)\n",
        " \n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train \u003d X_train / 255\n",
        "X_test \u003d X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train \u003d np_utils.to_categorical(y_train)\n",
        "y_test \u003d np_utils.to_categorical(y_test)\n",
        "num_classes \u003d y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Zzj4cLKd3W",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "This time we define a large CNN architecture with additional convolutional, max pooling layers and fully connected layers. The network topology can be summarized as follows.\n",
        "\n",
        "1 Convolutional layer with 30 feature maps of size 5×5.\n",
        "2 Pooling layer taking the max over 2*2 patches.\n",
        "3 Convolutional layer with 15 feature maps of size 3×3.\n",
        "4 Pooling layer taking the max over 2*2 patches.\n",
        "5 Dropout layer with a probability of 20%.\n",
        "6 Flatten layer.\n",
        "7 Fully connected layer with 128 neurons and rectifier activation.\n",
        "8 Fully connected layer with 50 neurons and rectifier activation.\n",
        "9 Output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGS1mGf7Kd3X",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "def larger_model():\n",
        "\t# create model\n",
        "\tmodel \u003d Sequential()\n",
        "\tmodel.add(Convolution2D(30, (5, 5), padding\u003d\u0027valid\u0027, input_shape\u003d(28, 28, 1), activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\tmodel.add(Convolution2D(15, (3, 3), activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(Dense(50, activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(Dense(num_classes, activation\u003d\u0027softmax\u0027))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ylAS3gkKd3Y",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Like the previous two experiments, the model is fit over 10 epochs with a batch size of 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hixJCZCrKd3Z",
        "colab_type": "code",
        "outputId": "9997a433-ac20-4509-de71-0c6a041c37fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "pycharm": {}
      },
      "source": [
        "# build the model\n",
        "model \u003d larger_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data\u003d(X_test, y_test), epochs\u003d10, batch_size\u003d200, verbose\u003d2)\n",
        "# Final evaluation of the model\n",
        "scores \u003d model.evaluate(X_test, y_test, verbose\u003d0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.3808 - acc: 0.8837 - val_loss: 0.0818 - val_acc: 0.9750\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1024 - acc: 0.9686 - val_loss: 0.0597 - val_acc: 0.9788\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0730 - acc: 0.9778 - val_loss: 0.0396 - val_acc: 0.9878\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0594 - acc: 0.9818 - val_loss: 0.0352 - val_acc: 0.9883\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0498 - acc: 0.9842 - val_loss: 0.0355 - val_acc: 0.9889\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0448 - acc: 0.9859 - val_loss: 0.0290 - val_acc: 0.9910\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0380 - acc: 0.9882 - val_loss: 0.0329 - val_acc: 0.9889\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0365 - acc: 0.9884 - val_loss: 0.0279 - val_acc: 0.9901\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0307 - acc: 0.9905 - val_loss: 0.0230 - val_acc: 0.9928\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0294 - acc: 0.9900 - val_loss: 0.0271 - val_acc: 0.9910\n",
            "Baseline Error: 0.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNtAqhAKd3b",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Running the example prints accuracy on the training and validation datasets each epoch and a final classification error rate.\n",
        "\n",
        "The model takes about a couple of seconds to run per epoch on a GPU (CPU run times are around 60s/epoch). This slightly larger model achieves the respectable classification error rate of 0.84%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rWJKCAEKd3b",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "Using TensorFlow backend.\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "Epoch 1/10\n",
        "2018-01-21 14:51:56.002201: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:51:56.002228: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:51:56.256299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
        "2018-01-21 14:51:56.257014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
        "name: GeForce GTX TITAN X\n",
        "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
        "pciBusID 0000:02:00.0\n",
        "Total memory: 11.92GiB\n",
        "Free memory: 11.80GiB\n",
        "2018-01-21 14:51:56.257063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
        "2018-01-21 14:51:56.257072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
        "2018-01-21 14:51:56.257082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -\u003e (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)\n",
        "3s - loss: 0.3846 - acc: 0.8830 - val_loss: 0.0805 - val_acc: 0.9754\n",
        "Epoch 2/10\n",
        "2s - loss: 0.1002 - acc: 0.9688 - val_loss: 0.0605 - val_acc: 0.9791\n",
        "Epoch 3/10\n",
        "2s - loss: 0.0721 - acc: 0.9780 - val_loss: 0.0393 - val_acc: 0.9877\n",
        "Epoch 4/10\n",
        "2s - loss: 0.0580 - acc: 0.9819 - val_loss: 0.0357 - val_acc: 0.9884\n",
        "Epoch 5/10\n",
        "2s - loss: 0.0487 - acc: 0.9844 - val_loss: 0.0343 - val_acc: 0.9898\n",
        "Epoch 6/10\n",
        "2s - loss: 0.0436 - acc: 0.9862 - val_loss: 0.0281 - val_acc: 0.9916\n",
        "Epoch 7/10\n",
        "2s - loss: 0.0378 - acc: 0.9882 - val_loss: 0.0328 - val_acc: 0.9886\n",
        "Epoch 8/10\n",
        "2s - loss: 0.0368 - acc: 0.9880 - val_loss: 0.0272 - val_acc: 0.9915\n",
        "Epoch 9/10\n",
        "2s - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0236 - val_acc: 0.9931\n",
        "Epoch 10/10\n",
        "2s - loss: 0.0303 - acc: 0.9902 - val_loss: 0.0262 - val_acc: 0.9916\n",
        "Baseline Error: 0.84%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsgLdlKLM43J",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "682bcR92Kd3d",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "## Saving models\n",
        "\n",
        "Being able to train a model is fine, but in practice once we\u0027ve trained the model we probably want to save the result so we can reuse it at a later time. Keras makes saving the model into an `HDF5` format file easy using `model.save(filepath)`. This will save the architecture of the model, the weights of the model, the training configuration (loss, optimizer) and the state of the optimizer, allowing to resume training exactly where you left off should you wish to continue training with more epochs.\n",
        "\n",
        "\u003e __Exercise:__ Can you modify the code for the previous CNN architecture to save the trained result into a file called `bettercnn.h5`?\n",
        "\n",
        "## Reading models and propagating input\n",
        "\n",
        "At this point, we know how to train a model and how to save the result. Lets assume we\u0027re in the business of building a real system for handwritten character recognition; we need to be able to read in a previously trained model and forward propagate an image from outside the MNIST dataset through it in order to generate a prediction. \n",
        "\n",
        "Firstly, let\u0027s download an image to use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z79mDIxKKd3d",
        "colab_type": "code",
        "outputId": "1346ead0-dd82-4595-952f-85324860f753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "pycharm": {}
      },
      "source": "!wget https://github.com/ecs-vlc/ml_workshop_2019/raw/master/Keras/part1/1.PNG",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-19 13:03:51--  https://github.com/jonhare/DISCnetMachineLearningCourse/raw/master/Thursday/practical-part1/1.PNG\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jonhare/DISCnetMachineLearningCourse/master/Thursday/practical-part1/1.PNG [following]\n",
            "--2019-05-19 13:03:52--  https://raw.githubusercontent.com/jonhare/DISCnetMachineLearningCourse/master/Thursday/practical-part1/1.PNG\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2448 (2.4K) [image/png]\n",
            "Saving to: ‘1.PNG’\n",
            "\n",
            "1.PNG               100%[\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e]   2.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-19 13:03:52 (60.6 MB/s) - ‘1.PNG’ saved [2448/2448]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MhIt8HrKd3g",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Now let\u0027s build some code load the model and apply it to the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qVYiYShKd3g",
        "colab_type": "code",
        "outputId": "ce3ceef5-b8f8-439e-e2b0-e856c640643a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "pycharm": {}
      },
      "source": [
        "import sys\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from imageio import imread\n",
        "\n",
        "# load a model\n",
        "#model \u003d load_model(\u0027bettercnn.h5\u0027)\n",
        "\n",
        "# load an image\n",
        "image \u003d imread(\u00271.PNG\u0027).astype(float)\n",
        "\n",
        "# normalise it in the same manner as we did for the training data\n",
        "image \u003d image / 255.0\n",
        "\n",
        "#reshape\n",
        "image \u003d image.reshape(1,28,28,1)\n",
        "\n",
        "# forward propagate and print index of most likely class \n",
        "# (for MNIST this corresponds one-to-one with the digit)\n",
        "plt.imshow(imread(\u00271.PNG\u0027), cmap\u003d\u0027gray\u0027)\n",
        "plt.show()\n",
        "print(\"predicted digit: \"+str(model.predict_classes(image)[0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1NT/A3lKqw6Thd0OAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cFigure size 432x288 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predicted digit: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaFa6xKOKd3j",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Running this should yield something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okRuy-gEKd3j",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "Using TensorFlow backend.\n",
        "2018-01-21 14:55:16.453161: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:55:16.453191: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn\u0027t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
        "2018-01-21 14:55:16.701871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
        "2018-01-21 14:55:16.702581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
        "name: GeForce GTX TITAN X\n",
        "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
        "pciBusID 0000:02:00.0\n",
        "Total memory: 11.92GiB\n",
        "Free memory: 11.80GiB\n",
        "2018-01-21 14:55:16.702605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
        "2018-01-21 14:55:16.702613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
        "2018-01-21 14:55:16.702623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -\u003e (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)\n",
        "1/1 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s\n",
        "predicted digit: 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_51ISBmJKd3l",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "\u003e __Exercise:__ Try with some other images and see what results you get. You can replace the 1 in the `wget` url above with anything between 0 and 9 to download some different digits, or create your own 24x24 pixel images.\n",
        "\n",
        "\u003e __Exercise:__ Rather than just outputting the most likely class, modify the code to print the weight distribution over the output layer using the `model.predict()` method instead of `model.predict_classes()`.\n",
        "\n",
        "## Visualising the first layers filters and responses\n",
        "\n",
        "In our previous convolutional network, the first layer was a Convolutional layer. Because this convolutional layer is applied directly to the greylevel input MNIST images the filters that are learned can themselves just be considered to be small (5x5 in this case) greylevel images. We can extract the weights of these filters directly from the trained network and visualise them using `matplotlib` like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH0xtBwLKd3l",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from imageio import imread\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load a model\n",
        "model \u003d load_model(\u0027bettercnn.h5\u0027)\n",
        "\n",
        "weights \u003d model.layers[0].get_weights()[0]\n",
        "\n",
        "# plot the first layer features\n",
        "for i in xrange(0,30):\n",
        "\tplt.subplot(5,6,i+1)\n",
        "\tplt.imshow(weights[:,:,0,i], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0rSCYk0Kd3n",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "Note that the ordering of convolution filters in Tensorflow is [width][height][pixels][depth].\n",
        "\n",
        "\u003e __Exercise:__ Run the above code and see what the filters look like.\n",
        "\n",
        "If we forward propagate an input through the network we can also visualise the response maps generated by the filters. The advantage of this kind of visualisation is that we can compute it at any layer, not just the first one. In order to do this in Keras, we must define a Keras function that will use the backend to propagate the given input through the network to the required point. The following code shows how this can be achieved to generate the response maps of the second convolutional layer of our network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xq8GhS-Kd3n",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from imageio import imread\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load a model\n",
        "model \u003d load_model(\u0027bettercnn.h5\u0027)\n",
        "\n",
        "# load an image\n",
        "image \u003d imread(\"1.PNG\").astype(float)\n",
        "\n",
        "# normalise it in the same manner as we did for the training data\n",
        "image \u003d image / 255.0\n",
        "\n",
        "# reshape\n",
        "image \u003d image.reshape(1,28,28,1)\n",
        "\n",
        "# define a keras function to extract the 3rd layer response maps\n",
        "get_3rd_layer_output \u003d K.function([model.layers[0].input],\n",
        "                                  [model.layers[2].output])\n",
        "layer_output \u003d get_3rd_layer_output([image])[0]\n",
        "\n",
        "# plot the results\n",
        "for i in xrange(0,15):\n",
        "\tplt.subplot(4,4,i+1)\n",
        "\tplt.imshow(layer_output[0,:,:,i], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgBhnDY6Kd3p",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "\u003e __Exercise:__ Run the above code and see how the response maps differ for different input images.\n",
        "\n",
        "A final way of visualising what the filters (at any depth) are learning is to find the input image that maximises the response of the filter. We can do this by starting with a random image and using gradient ascent to optimise the image to maximise the chosen filter. The following code snippet shows how this can be achieved, based on this article in the [Keras blog](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsBgTpDkKd3p",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load a model\n",
        "model \u003d load_model(\u0027bettercnn.h5\u0027)\n",
        "\n",
        "input_img \u003d model.input\n",
        "\n",
        "step\u003d1\n",
        "\n",
        "# we\u0027re interested in maximising outputs of the 3rd layer:\n",
        "layer_output \u003d model.layers[3].output\n",
        "\n",
        "for i in xrange(0,15):\n",
        "\t# build a loss function that maximizes the activation\n",
        "\t# of the nth filter of the layer considered\n",
        "\tloss \u003d K.mean(layer_output[:, :, :, i])\n",
        "\n",
        "\t# compute the gradient of the input picture wrt this loss\n",
        "\tgrads \u003d K.gradients(loss, input_img)[0]\n",
        "\n",
        "\t# normalization trick: we normalize the gradient\n",
        "\tgrads /\u003d (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "\t# this function returns the loss and grads given the input picture\n",
        "\titerate \u003d K.function([input_img], [loss, grads])\n",
        "\n",
        "\t# we start from a gray image with some noise\n",
        "\tinput_img_data \u003d np.random.random((1, 28, 28, 1)) * 0.07 + 0.5\n",
        "\t\n",
        "\t# run gradient ascent for 50 steps\n",
        "\tfor j in range(50):\n",
        "\t\tloss_value, grads_value \u003d iterate([input_img_data])\n",
        "\t\tinput_img_data +\u003d grads_value * step\n",
        "\n",
        "\t# plot the results\n",
        "\tplt.subplot(4,4,i+1)\n",
        "\tplt.imshow(input_img_data[0,:,:,0], cmap\u003dplt.get_cmap(\u0027gray\u0027))\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGIlGrOaKd3r",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "\u003e __Exercise:__ Run the above code to see what the filters respond to.\n",
        "\n",
        "## More advanced network topologies\n",
        "\n",
        "Recent network models, such as the deep residual network (ResNet) and GoogLeNet architectures, do not follow a straight path from input to output. Instead, these models incorporate branches and merges to create a computation graph. Branching and merging is easy to implement in Keras as show in the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c4VCMccKd3s",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Model\n",
        "\n",
        "def branch_model():\n",
        "\tmodel \u003d Sequential()\n",
        "\n",
        "\tx \u003d Input(shape\u003d(28, 28, 1))\n",
        "\tleft \u003d Convolution2D(16, (1, 1), padding\u003d\u0027same\u0027)(x)\n",
        "\tright \u003d Convolution2D(16, (5, 5), padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)(x)\n",
        "\ty \u003d add([left, right])\n",
        "\tblock \u003d Model(inputs\u003dx, outputs\u003dy)\n",
        "\n",
        "\tmodel.add(block)\n",
        "\tmodel.add(MaxPooling2D(pool_size\u003d(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation\u003d\u0027relu\u0027))\n",
        "\tmodel.add(Dense(num_classes, activation\u003d\u0027softmax\u0027))\n",
        "\t\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss\u003d\u0027categorical_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPNzbzE7Kd3t",
        "colab_type": "text",
        "pycharm": {}
      },
      "source": [
        "This defines a variant of our initial simple CNN model in which the input is split into two paths and then merged again; the left hand path consists of a 1x1 convolution layer, whilst the right-hand path has a 5x5 convolutional layer. The 1x1 convolutions will have the effect of increasing the number of bands in the input from 1 to 16 (with each band a [potentially different] scalar multiple of the input]. In this case the left and right branches are merged by summing them together (element-wise, layer by layer).\n",
        "\n",
        "\u003e __Exercise:__ Try running the above network model on the MNIST data. What accuracy do you achieve?\n",
        "\n",
        "## Going further\n",
        "\n",
        "None of the network topology we have experimented with thus far are optimised. Nor are they reproductions of network topologies from recent papers.\n",
        "\n",
        "\u003e __Exercise:__ There is a lot of opportunity for you to tune and improve upon these models. What is the best error rate score you can achieve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEWzpO4Myty",
        "colab_type": "code",
        "colab": {},
        "pycharm": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}